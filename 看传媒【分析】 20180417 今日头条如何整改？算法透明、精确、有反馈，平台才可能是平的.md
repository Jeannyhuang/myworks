## 今日头条如何整改？算法透明、精确、有反馈，平台才可能是平的

本文首发于看传媒。[原址链接](https://mp.weixin.qq.com/s/z5H7rV5mbpBH5tGRBRChDw) 2018.4.17

导读：“你们文化人给了我们太多深刻的命题。”一年多前，在面对《财经》记者关于算法与人性的质问时，张一鸣回答地天真烂漫。问题是无法逃避的，近段时间，这位年轻的CEO正面临着一系列的产品整改，面临着主管部门和文化人们给予的更深刻的拷问：平台、媒体、科技、价值观之间的关系。请看浙江理工大学青年学子黄佶滢的观察与分析。



### *平台是平的吗？*

今日头条已经俨然成为这个时代最强势的媒体平台之一，每天有7000多万人花76分钟在今日头条上，将这个平台作为自己信息获取的主要来源。然而，“平台”这个词天生具有一种欺骗性质的诱惑性，正像研究员Tarleton Gillespie指出的那样，这个比喻正在严重误导着人们。用户常认为平台真的是“平”的，平台是平等地开放给所有人的，每个人都能从中平等地获取信息。实际上，我们每个人见到的信息都被赋予了不同的权重，每条信息都带着其特有的算法和目的蹦跳到我们眼前，总有一些信息你总能看到，而另一些则永远也看不到。今日头条根据你的喜好和习惯来呈现信息，微博也早已将信息流从时间顺序改为算法排序，让那些两天前的“重要信息”跃到3分钟前的好友动态之上。归根结底，公司的目标都是相同的，让这些信息更精准地变现。

同时，平台总让人觉得它是不用承担责任的，就像车站的站台，它只是一个承载的工具，至于承载的内容是什么则与工具无关。然而，如今日头条的科技公司们早已不是一个简单的、中立的、可以免责的工具。人们依靠多样的信息来充实自己的头脑，就如同用不同的食物填饱自己的胃，不同的信息搭配构建了不同的媒体食谱，长久接触下去会直接塑造人的很多方面，包括怎样看到世界，塑造怎样的价值观，怎样与公共空间打交道。

当一个算法影响的是亿万人每天能接触到什么，甚至能改变他们的认知形态与交流形态时，其背后的公司决策者、设计算法的工程师，应该对它保持一颗敬畏之心。



### *算法是中立的吗？*

算法中的媒体比较像《绿野仙踪》中的世界：我们看不到参与其中的人。技术看起来是我们与朋友、与信息间仅有的媒介，它潜藏在平台之下，我们并不会去思考技术如何干涉我们看到的东西。采访中，张一鸣曾表示“我们不是个媒体公司，是因为我们不创造内容，我们不发表观点。我们是一家科技公司，是为了解决问题（信息分发问题）而创办的，充分认识问题比如何解决问题更重要。你认识到一个问题、认识到这个问题的规模和意义，这本身就是一半的答案。”看上去，他真的相信技术是中立的，是没有价值观的。 

然而深入一想，就会立刻发现问题：用户看到的世界并不是张一鸣描述的完整的世界，认识到的是怎样的问题、具有怎样的规模并不受自己控制，而是依靠算法。“提高分发效率，满足用户需求”这种理工科思维，实际上规避了很多硬核问题，比如，道德、价值观。在技术处理中，越具体的、能转化为数字的越容易被计算机所运算，符合这一条件的算法模型将会受到很好的运用。比如棒球比赛的算法则被公认为公平的、正向循环的算法。它具有良好算法的三大特性：透明、精确、有反馈。首先，因为比赛是公开的，人人都能获取运动员相关的数据——采用了什么样的动作和技巧，获得了多少分；其次，棒球的统计相当精确，数据直接与运动员的表现相联，并且与预测高度相关；最后，棒球的算法有明显的反馈系统，设计者可以根据比赛的结果与算法的预测相对比，了解哪里出错了，并且由于比赛不断进行，得到的反馈也不断更新，推动算法根据实际情况进行改变。

反观今日头条的算法，第一，算法是不透明的，用户并不知道平台是通过他们怎样的行为来确定推送信息。

第二，今日头条不靠编辑，依靠算法来控制信息的产出。你也许会说，算法不会让事情变得更坏，比如曾经的编辑也会根据自己的喜好偏见来筛选题材，控制人们看到的东西，但人类决策有一个重大的好处，它是会演变的。一个编辑随着年龄的增加，阅历的增长，社会在不断地带给他反馈，他由此不断地调整所认同的价值观。相比之下，算法则会一直不变，除非工程师介入系统。算法将某种历史状态写进程式里，它们不创造未来。此外，在“个人喜好”、“价值观”中，许多人类才有的概念是无法精确量化的，算法是人设计的，而建模者极少愿意多费一些力气去纳入这些价值判断，这似乎太困难了，他们关注某些行为，但找不到直接相关的数据，于是用另一些数据代替。比如设计者可能根据一个人的地理位置和文化水平判断他是否足够富裕来推送借贷广告，而这实际上是涉嫌歧视的。

第三，今日头条的算法缺乏有力的反馈系统，你若不慎点击了那条借贷广告，接下来的几天就会有大量的借贷信息向你涌来，用户却没有办法点击“不需要”来进行反馈。这还属于用户“意识到”自己不需要的情况，更多的时候，用户被算法不知不觉地禁锢在了一个“过滤气泡”中——算法根据我们的个人信息和此前的阅读行为，社交媒体、搜索引擎或阅读类app会为我们过滤掉和我们意见不一致的信息，让人们活在一个个泡泡里面。这些引人入胜的技术发生在封闭的程式里和严密的防火墙内，将我们每个人安置在各自隐蔽的、惬意的角落。

 

### *算法一定会让我们在过滤气泡中越走越窄吗？*

答案是否定的。我们熟悉的根据“相似性”推荐信息只是算法的一个方面，《Recommender System Handbook》一书中列举了多项推荐系统衡量指标，比如用户喜好、覆盖面、 信任、新鲜感、惊喜度、多样性等，最终呈现给用户的结果是算法在优化、权重这些指标的复杂结果。如果通过一定的建模手段，把多样性、新鲜度等指标放入模型中进行优化，最终看到的推送内容就有可能走出过滤气泡。

![img](https://mmbiz.qpic.cn/mmbiz_png/FriaLUnFMD3uaOLx7IpXN3ibRMThFSB2bcnAHcrgkaegH2rtKCoXuXHo1WbY6f78riauHRSlDTqWtibV5NDhQIHBicQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

美国国家公共广播（NPR）开发的名为“NPR One”的app，就致力于打破这一困境。NPR One将信息分为两类，重要的新闻不通过算法选择，而通过资深的编辑进行强有力的人工干预；重大新闻之外的“谈资”类信息则由算法推荐，值得一提的是，app每过一段时间就会向读者发出询问：“你真敢兴趣这些内容吗？”“看看别的好不好？”这种简单的操作给予了用户反馈的机会，让算法不断地纳入新的数据进行调整。此外，当你听取了事件的一方观点时，app会主动提醒你听取另一方观点；当时间发生后续反转时，算法会选出看过前期报道的人向他们递推后续新闻。

另一个值得学习的案例是由MIT媒体实验室发布的gobo，这个app是个第三方软件，通过让用户根据自己的想法调整参数来更改Twitter和Facebook等社交媒体的算法，让自主权回到用户手中，在app中用户能够自行决定信息流当中严肃新闻的比例、性别的比例和贴文的流行程度等六个参数，每一个参数的工作原理都会被明确告知。

建立过滤气泡的是算法，而打破泡泡的也正是算法本身，说到底如何制定算法取决于公司的价值观，取决于社会责任与商业利益的博弈，如今的互联网公司已经不能将社会责任与商业利益割离开来，两者已经紧密地结合在了一起，每一条信息的分发都展示着商业利益和社会责任的不同权重，满足商业利益的基础上尽到社会责任是极不负责任的。

美联社产品经理Ken Romano表示：技术应该支持对新闻内容的个性化体验，但不应该成为一切的决定者。平台对于算法的态度也应该如此，算法应该是我们的工具，而非我们是主人。我们的平台应该在设计中更精准，注重用户信息的安全性，同时像棒球算法那样更加透明，将尽可能多的数据原理提供给用户；更加精准，不用算法对价值观进行一刀切判断，在重大问题以及无法量化的问题上，用人与经验进行调节；更要建立起反馈机制，使用户不处于被动，使算法成为一个不断更新调整的良性系统。在社会责任与商业利益的博弈中，法规也需要对责任做出明确的规定，才能打造一个公平、清朗的平台社会，更好地推动公平与民主。



